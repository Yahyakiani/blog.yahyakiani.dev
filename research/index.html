<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Research Progress: Evaluating Model Editing for Natural Language Generation | Yahya Kayani</title><meta name=keywords content="NLP,Model Editing,Natural Language Generation,Research Update"><meta name=description content="Starting on a new research to evaluate model editing in natural language generation."><meta name=author content="Yahya Kayani"><link rel=canonical href=https://canonical.url/to/page><link crossorigin=anonymous href=/blog.yahyakiani.dev/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><link rel=icon href=http://yahyakiani.github.io/blog.yahyakiani.dev/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://yahyakiani.github.io/blog.yahyakiani.dev/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://yahyakiani.github.io/blog.yahyakiani.dev/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://yahyakiani.github.io/blog.yahyakiani.dev/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://yahyakiani.github.io/blog.yahyakiani.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://yahyakiani.github.io/blog.yahyakiani.dev/research/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Research Progress: Evaluating Model Editing for Natural Language Generation"><meta property="og:description" content="Starting on a new research to evaluate model editing in natural language generation."><meta property="og:type" content="website"><meta property="og:url" content="http://yahyakiani.github.io/blog.yahyakiani.dev/research/"><meta property="og:image" content="http://yahyakiani.github.io/blog.yahyakiani.dev/%3Cimage%20path/url%3E"><meta property="og:site_name" content="Yahya Kayani's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://yahyakiani.github.io/blog.yahyakiani.dev/%3Cimage%20path/url%3E"><meta name=twitter:title content="Research Progress: Evaluating Model Editing for Natural Language Generation"><meta name=twitter:description content="Starting on a new research to evaluate model editing in natural language generation."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Research Progress: Evaluating Model Editing for Natural Language Generation","item":"http://yahyakiani.github.io/blog.yahyakiani.dev/research/"}]}</script></head><body class="list dark" id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/ accesskey=h title="Home (Alt + H)"><img src=http://yahyakiani.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/ title=Home><span>Home</span></a></li><li><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/about/ title=About><span>About</span></a></li><li><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/experience/ title=Experience><span>Experience</span></a></li><li><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/projects/ title=Projects><span>Projects</span></a></li><li><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/skills/ title=Skills><span>Skills</span></a></li><li><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/blog/ title=Blog><span>Blog</span></a></li><li><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/resume/ title=Résumé><span>Résumé</span></a></li><li><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/research/ title="Research Papers"><span class=active>Research Papers</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=http://yahyakiani.github.io/blog.yahyakiani.dev/>Home</a></div><h1>Research Progress: Evaluating Model Editing for Natural Language Generation
<a href=/blog.yahyakiani.dev/research/index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1><div class=post-description>Starting on a new research to evaluate model editing in natural language generation.</div></header><div class=post-content><h2 id=september-23-2023-embarking-on-model-editing-evaluation><strong>September 23, 2023: Embarking on Model Editing Evaluation</strong><a hidden class=anchor aria-hidden=true href=#september-23-2023-embarking-on-model-editing-evaluation>#</a></h2><h3 id=research-leadership><strong>Research Leadership</strong><a hidden class=anchor aria-hidden=true href=#research-leadership>#</a></h3><p>This research is spearheaded by <a href=https://github.com/domenicrosati>Domenic Rosati</a>. Domenic is pivotal in bringing this project to completion and bringing the team up to speed. Collaborating closely with him on this initiative are Yahya(Me), Melis, and Deepika.</p><h3 id=research-objective><strong>Research Objective</strong><a hidden class=anchor aria-hidden=true href=#research-objective>#</a></h3><p>The primary aim of this project is to establish a framework for assessing paragraph-length generations from edited large language models. As the capabilities of large language models grow, so does the importance of understanding their behavior, especially when edited.</p><h3 id=collaborative-effort><strong>Collaborative Effort</strong><a hidden class=anchor aria-hidden=true href=#collaborative-effort>#</a></h3><p>This research is a collaborative initiative involving:</p><ul><li>Domenic, Yahya, Deepika, Melis.</li><li>Supervisors: Lizbeth Escobedo, Hassan Sajjad, Frank Rudzicz</li><li>External Collaborators: Jason (from Counterfact+ dataset), Andrew</li></ul><p>Relevant Resources:</p><ul><li><a href=https://www.zotero.org/groups/5187924/long-form-model-edit-eval>Zotero Group</a></li><li><a href=https://www.overleaf.com/4737549179znvrxghfcyqg>Overleaf Paper Draft</a></li><li><a href=https://github.com/domenicrosati/longform_edit_model_evals>Github Repository</a></li></ul><h4 id=weekly-meeting-time><strong>Weekly Meeting Time</strong><a hidden class=anchor aria-hidden=true href=#weekly-meeting-time>#</a></h4><p>Our team has set a weekly meeting every Wednesday from 10am to 11am AST to discuss progress, issues, and next steps.</p><h3 id=initial-steps><strong>Initial Steps</strong><a hidden class=anchor aria-hidden=true href=#initial-steps>#</a></h3><p>Our first task was to design a 10-passage survey aimed at discerning various properties and values related to model editing. The design specifics and outcomes of this survey will be detailed in the next update.</p><h3 id=resources--readings><strong>Resources & Readings</strong><a hidden class=anchor aria-hidden=true href=#resources--readings>#</a></h3><p>As we dive into this project, several readings and resources have been suggested by Domenic to lay a basic understanding of the subject matter:</p><ul><li>Basics: An understanding of neural networks, transformers, tokens, and more.</li><li>Papers: From understanding the risks posed by language models to evaluating the ripple effects of knowledge editing.</li></ul><h2 id=october-7-2023-week-1-milestones-and-tasks><strong>October 7, 2023: Week 1 Milestones and Tasks</strong><a hidden class=anchor aria-hidden=true href=#october-7-2023-week-1-milestones-and-tasks>#</a></h2><h3 id=this-weeks-milestone-introduction><strong>This Week&rsquo;s Milestone: Introduction</strong><a hidden class=anchor aria-hidden=true href=#this-weeks-milestone-introduction>#</a></h3><h4 id=goals><strong>Goals</strong><a hidden class=anchor aria-hidden=true href=#goals>#</a></h4><ul><li>Understand the overall project and its objectives.</li><li>Familiarize ourselves with the background necessary for writing the introduction section.</li><li>Frame an introduction for our paper.</li><li>Pick a motivation paper to read for next week.</li><li>Read and understand the editing survey we have designed.</li></ul><h4 id=slides><strong>Slides</strong><a hidden class=anchor aria-hidden=true href=#slides>#</a></h4><ul><li>Slides for this week will focus on the above-mentioned goals.</li></ul><h4 id=to-do-for-next-week><strong>To-Do for Next Week</strong><a hidden class=anchor aria-hidden=true href=#to-do-for-next-week>#</a></h4><h5 id=pick-motivation-paper-to-look-at><strong>Pick Motivation Paper to Look At</strong><a hidden class=anchor aria-hidden=true href=#pick-motivation-paper-to-look-at>#</a></h5><p>We have identified several papers that can serve as motivation for our work:</p><ul><li>Petroni, F., et al. (2019). &ldquo;Language models as knowledge bases?&rdquo;.</li><li>Jiang, Z., et al. (2020). &ldquo;How can we know what language models know?&rdquo;.</li><li>Elazar, Y., et al. (2021). &ldquo;Measuring and improving consistency in pretrained language models&rdquo;.</li><li>Lin, S., et al. (2021). &ldquo;Truthfulqa: Measuring how models mimic human falsehoods&rdquo;.</li><li>Gehman, S., et al. (2020). &ldquo;Realtoxicityprompts: Evaluating neural toxic degeneration in language models&rdquo;.</li><li>Bender, E. M., et al. (2021). &ldquo;On the dangers of stochastic parrots: Can language models be too big?&rdquo;.</li><li>Weidinger, L., et al. (2022). &ldquo;Taxonomy of Risks posed by Language Models&rdquo;.</li></ul><h5 id=all-of-us-read><strong>All of Us Read</strong><a hidden class=anchor aria-hidden=true href=#all-of-us-read>#</a></h5><ul><li>Yao, Y., et al. (2023). &ldquo;Editing Large Language Models: Problems, Methods, and Opportunities&rdquo;.</li><li>Visit the webpage: <a href=https://rome.baulab.info/>Rome Lab</a></li><li>Read Appendix J and Counterfactual AI Writing Study in <a href=https://arxiv.org/pdf/2202.05262.pdf>Arxiv Paper</a></li></ul><h2 id=october-14-2023-week-2-milestones-and-tasks><strong>October 14, 2023: Week 2 Milestones and Tasks</strong><a hidden class=anchor aria-hidden=true href=#october-14-2023-week-2-milestones-and-tasks>#</a></h2><h3 id=last-week-recap><strong>Last Week Recap</strong><a hidden class=anchor aria-hidden=true href=#last-week-recap>#</a></h3><h4 id=questions-and-feedback><strong>Questions and Feedback</strong><a hidden class=anchor aria-hidden=true href=#questions-and-feedback>#</a></h4><ul><li>Addressed questions about model editing.</li><li>Discussed pre-test feedback, including issues with paragraph length and clarity of terminologies used for annotation.</li></ul><h3 id=this-weeks-milestone-related-works-and-survey-deployment><strong>This Week&rsquo;s Milestone: Related Works and Survey Deployment</strong><a hidden class=anchor aria-hidden=true href=#this-weeks-milestone-related-works-and-survey-deployment>#</a></h3><h4 id=goals-1><strong>Goals</strong><a hidden class=anchor aria-hidden=true href=#goals-1>#</a></h4><ul><li>Delve into related works, focusing on model editing and evaluation of model editing.</li><li>Deploy the survey designed in Week 1.</li></ul><h4 id=slides-1><strong>Slides</strong><a hidden class=anchor aria-hidden=true href=#slides-1>#</a></h4><ul><li>Slides for this week will center on the above goals.</li></ul><h3 id=to-do-for-next-week-1><strong>To-Do for Next Week</strong><a hidden class=anchor aria-hidden=true href=#to-do-for-next-week-1>#</a></h3><h4 id=annotation-project><strong>Annotation Project</strong><a hidden class=anchor aria-hidden=true href=#annotation-project>#</a></h4><ul><li><p><strong>Reading (All - Optional):</strong></p><ul><li>Papers on annotation best practices and quality management.</li></ul></li><li><p><strong>Brainstorm by Freeform Annotating:</strong></p><ul><li>Group 1 (Dom)</li><li>Group 2 (Deepika)</li><li>Group 3 (Yahya)</li><li>Group 4 (Melis)</li></ul></li><li><p><strong>Other Tasks:</strong></p><ul><li>Develop a draft of Annotation Guidelines (Dom)</li><li>Select a Platform for Annotations (Dom)</li><li>Identify a Dataset for Annotation (Dom)</li></ul></li></ul><h3 id=annotation-session-and-feedback><strong>Annotation Session and Feedback</strong><a hidden class=anchor aria-hidden=true href=#annotation-session-and-feedback>#</a></h3><h4 id=session-overview><strong>Session Overview</strong><a hidden class=anchor aria-hidden=true href=#session-overview>#</a></h4><ul><li>All team members participated in an annotation session.</li><li>We followed the annotation guidelines to label pairs of sentences as consistent, inconsistent, or neutral.</li></ul><h4 id=issues-and-feedback><strong>Issues and Feedback</strong><a hidden class=anchor aria-hidden=true href=#issues-and-feedback>#</a></h4><ul><li>The paragraphs for annotation were found to be too long, making the task cumbersome.</li><li>Some terminologies used in the annotation guidelines were confusing.</li></ul><h4 id=action-items-for-next-annotation-session><strong>Action Items for Next Annotation Session</strong><a hidden class=anchor aria-hidden=true href=#action-items-for-next-annotation-session>#</a></h4><ul><li>Shorten the paragraphs to be annotated.</li><li>Clarify terminologies and guidelines for annotation.</li></ul><h3 id=annotation-instructions><strong>Annotation Instructions</strong><a hidden class=anchor aria-hidden=true href=#annotation-instructions>#</a></h3><h4 id=task-description><strong>Task Description</strong><a hidden class=anchor aria-hidden=true href=#task-description>#</a></h4><p>In this task, you will read pairs of sentences and label them as consistent, inconsistent, or neutral.</p><h4 id=guidelines><strong>Guidelines</strong><a hidden class=anchor aria-hidden=true href=#guidelines>#</a></h4><ul><li><strong>Consistent Sentence Pair</strong>: A pair of sentences that agree with each other.<ul><li><strong>Example</strong>: The Eiffel Tower is in Rome. / Rome is home to the world famous Eiffel Tower.</li></ul></li><li><strong>Inconsistent Sentence Pair</strong>: A pair of sentences that contradict each other.<ul><li><strong>Example</strong>: The Eiffel Tower is in Rome. / Paris is home to the world famous Eiffel Tower.</li></ul></li><li><strong>Neutral Sentence Pair</strong>: A pair of sentences that is neither consistent nor inconsistent.<ul><li><strong>Example</strong>: The Eiffel Tower is in Rome. / Paris is a wonderful city to visit.</li></ul></li></ul><h4 id=note><strong>Note</strong><a hidden class=anchor aria-hidden=true href=#note>#</a></h4><p>The focus is not on the factual accuracy of the sentences but on their consistency or inconsistency with each other.</p><h2 id=october-21-2023-week-3-milestones-and-tasks><strong>October 21, 2023: Week 3 Milestones and Tasks</strong><a hidden class=anchor aria-hidden=true href=#october-21-2023-week-3-milestones-and-tasks>#</a></h2><h3 id=last-week-recap-1><strong>Last Week Recap</strong><a hidden class=anchor aria-hidden=true href=#last-week-recap-1>#</a></h3><ul><li>Deployed the survey designed in earlier weeks.</li><li>Discussed related works.</li><li>Conducted a pre-study on annotations.</li></ul><h3 id=this-weeks-milestone-methods-for-data-collection-and-annotation-guidelines><strong>This Week&rsquo;s Milestone: Methods for Data Collection and Annotation Guidelines</strong><a hidden class=anchor aria-hidden=true href=#this-weeks-milestone-methods-for-data-collection-and-annotation-guidelines>#</a></h3><h4 id=goals-2><strong>Goals</strong><a hidden class=anchor aria-hidden=true href=#goals-2>#</a></h4><ul><li>Finalize methods for data collection.</li><li>Update Annotation Guidelines based on feedback and discussions.</li><li>Pilot the new annotation guidelines.</li></ul><h4 id=slides-2><strong>Slides</strong><a hidden class=anchor aria-hidden=true href=#slides-2>#</a></h4><ul><li>Slides for this week will encapsulate the above goals.</li></ul><h3 id=updated-annotation-guidelines><strong>Updated Annotation Guidelines</strong><a hidden class=anchor aria-hidden=true href=#updated-annotation-guidelines>#</a></h3><h4 id=changes><strong>Changes</strong><a hidden class=anchor aria-hidden=true href=#changes>#</a></h4><ul><li><p><strong>Video Tutorial</strong>: A <a href="https://www.loom.com/share/acb1231f2b774e60b8503e87654adfc5?sid=4959f30b-d350-4f2a-85b5-073b7d70f613">video</a> was made to explain the new guidelines.</p></li><li><p><strong>Instructions</strong>: The task now involves reading a passage of text and labeling a claim about that passage.</p></li><li><p><strong>Classification</strong>: The task has two parts:</p><ol><li>Classifying the passage as supporting, contradicting, or neutral towards the claim.</li><li>Highlighting sentences that support or contradict the claim (if applicable).</li></ol></li><li><p><strong>Examples</strong>: New examples were provided to illustrate what supporting, contradicting, and neutral passages look like.</p></li></ul><h3 id=to-do-for-next-week-2><strong>To-Do for Next Week</strong><a hidden class=anchor aria-hidden=true href=#to-do-for-next-week-2>#</a></h3><ul><li>Show <a href=https://hypermatrix.lighttag.io/label>HyperMatrix Annotation Platform</a>.</li><li>Send reminders to those who haven&rsquo;t completed the survey.</li><li>Provide feedback on the annotation proposal.</li><li>Discuss the analysis plan for the survey.</li></ul><h4 id=round-table-and-annotations-discussion><strong>Round Table and Annotations Discussion</strong><a hidden class=anchor aria-hidden=true href=#round-table-and-annotations-discussion>#</a></h4><ul><li>A round table discussion will be conducted to discuss the new annotation guidelines and the pilot study.</li></ul><h2 id=october-28-2023-week-4-milestones-and-tasks><strong>October 28, 2023: Week 4 Milestones and Tasks</strong><a hidden class=anchor aria-hidden=true href=#october-28-2023-week-4-milestones-and-tasks>#</a></h2><h3 id=last-week-recap-2><strong>Last Week Recap</strong><a hidden class=anchor aria-hidden=true href=#last-week-recap-2>#</a></h3><ul><li>Conducted an annotation pretest.</li><li>Krippendorff&rsquo;s Alpha was measured to be 0.54.</li></ul><h3 id=this-weeks-milestone-achieve-higher-agreement><strong>This Week&rsquo;s Milestone: Achieve Higher Agreement</strong><a hidden class=anchor aria-hidden=true href=#this-weeks-milestone-achieve-higher-agreement>#</a></h3><h4 id=goals-3><strong>Goals</strong><a hidden class=anchor aria-hidden=true href=#goals-3>#</a></h4><ul><li>Aim for higher agreement among annotators.</li><li>Discuss discrepancies and plan for improvement.</li></ul><h4 id=slides-3><strong>Slides</strong><a hidden class=anchor aria-hidden=true href=#slides-3>#</a></h4><ul><li>Slides will focus on achieving higher inter-rater reliability and discussing disagreements.</li></ul><h3 id=round-table-and-disagreement-discussion><strong>Round Table and Disagreement Discussion</strong><a hidden class=anchor aria-hidden=true href=#round-table-and-disagreement-discussion>#</a></h3><ul><li>A round table discussion will be held to openly discuss disagreements among annotations.</li><li>Annotations will be reviewed on <a href=https://lighttag.io/>Light Tag</a>.</li><li>Annotation guidelines will be revised and can be found <a href=https://docs.google.com/document/d/1Ar1X7FZa5obS_vhL556VY9IJXq3cwoY_MwtBYufj8ww/edit>here</a>.</li></ul><h3 id=to-do-for-next-week-3><strong>To-Do for Next Week</strong><a hidden class=anchor aria-hidden=true href=#to-do-for-next-week-3>#</a></h3><h4 id=pretest-and-annotation-strategies><strong>Pretest and Annotation Strategies</strong><a hidden class=anchor aria-hidden=true href=#pretest-and-annotation-strategies>#</a></h4><ul><li>Conduct another pretest.</li><li>Based on the pretest results:<ul><li>If Inter-Rater Reliability (IRR) is less than ( \alpha = 0.7 ), annotations will be split 2 ways.</li><li>If IRR is high, annotations will be split 4 ways.</li></ul></li></ul><h4 id=handling-missing-context><strong>Handling Missing Context</strong><a hidden class=anchor aria-hidden=true href=#handling-missing-context>#</a></h4><ul><li>Missing context in annotations was identified as a challenge.</li><li>Two paths for addressing this:<ol><li>Provide the whole paragraph along with the sentence to be measured.</li><li>Keep it at sentence pairs with a rule: if you don’t have enough information, label it as neutral.</li></ol></li></ul><h4 id=other-tasks><strong>Other Tasks</strong><a hidden class=anchor aria-hidden=true href=#other-tasks>#</a></h4><ul><li>Open the option for open text feedback.</li><li>Complete 300 annotations.</li><li>I (Yahya) will look into resources for training DeBERTa V3 on annotations, starting with <a href="https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt">this course</a>.</li></ul><h2 id=glossary-and-context><strong>Glossary and Context</strong><a hidden class=anchor aria-hidden=true href=#glossary-and-context>#</a></h2><h3 id=inter-rater-reliability-irr><strong>Inter-Rater Reliability (IRR)</strong><a hidden class=anchor aria-hidden=true href=#inter-rater-reliability-irr>#</a></h3><ul><li><p><strong>What it is</strong>: Inter-Rater Reliability (IRR) is a metric used to measure the degree of agreement among multiple raters or annotators.</p></li><li><p><strong>What it&rsquo;s for</strong>: In the context of this project, IRR is important for ensuring that the annotations being made by different team members are consistent and reliable. This helps in the validation of the dataset being created.</p></li></ul><h3 id=krippendorffs-alpha><strong>Krippendorff&rsquo;s Alpha</strong><a hidden class=anchor aria-hidden=true href=#krippendorffs-alpha>#</a></h3><ul><li><p><strong>What it is</strong>: Krippendorff&rsquo;s Alpha is a statistical measure used to determine the reliability of agreement among multiple coders. It is a more general form of the Cronbach&rsquo;s alpha and can be applied to any number of coders providing ordinal, interval, or ratio data.</p></li><li><p><strong>What it&rsquo;s for</strong>: In this project, Krippendorff&rsquo;s Alpha is used as a specific method to quantify IRR. It helps identify how much of the variation in the data can be attributed to the reliability of the annotators.</p></li></ul><h3 id=the-need-for-higher-agreement><strong>The Need for Higher Agreement</strong><a hidden class=anchor aria-hidden=true href=#the-need-for-higher-agreement>#</a></h3><ul><li><strong>Why it&rsquo;s important</strong>: Achieving higher agreement among annotators is crucial for the validity and reliability of the data being generated. It ensures that the interpretations of the text are consistent, thereby making the conclusions drawn from the data more robust.</li></ul><h1 id=overview-of-the-projects-technical-progress>Overview of the Project&rsquo;s Technical Progress<a hidden class=anchor aria-hidden=true href=#overview-of-the-projects-technical-progress>#</a></h1><p>In the final stages of our annotation accuracy project, significant technical contributions were made to enhance the reliability of our data analysis methods. A pivotal aspect of this project involved the training and fine-tuning of the DeBERTa V3 model, which played a crucial role in improving our understanding of annotator agreement and classification accuracy.</p><h2 id=deep-dive-into-deberta-model-training>Deep Dive into DeBERTa Model Training<a hidden class=anchor aria-hidden=true href=#deep-dive-into-deberta-model-training>#</a></h2><p>Utilizing the DeBERTa (Decoding-enhanced BERT with Disentangled Attention) model, I refined our annotation model. The model was trained on a meticulously prepared dataset where class proportions were balanced based on prior analysis:</p><ul><li>Supports: 54.5752%</li><li>Contradicts: 24.4009%</li><li>Neutral: 21.0240%</li></ul><p>This distribution ensured that our model could effectively learn from a balanced set of examples, reducing bias and improving the generalizability of the model.</p><h2 id=model-performance-and-enhancements>Model Performance and Enhancements<a hidden class=anchor aria-hidden=true href=#model-performance-and-enhancements>#</a></h2><p>Post-training, the DeBERTa model exhibited a substantial increase in inter-rater reliability, achieving an Inter-Rater Reliability (IRR) score well above our initial benchmarks. This was a significant improvement from earlier models and set a new standard for our project&rsquo;s annotation accuracy.</p><h2 id=publication-and-recognition>Publication and Recognition<a hidden class=anchor aria-hidden=true href=#publication-and-recognition>#</a></h2><p>The results of this research and model training were submitted to a NAACL 2024 conference. I am pleased to report that our paper was accepted for publication, which marks a significant achievement for the team and underscores the quality and importance of our work.</p><p>The published paper can be accessed here: <a href=https://arxiv.org/abs/2402.09394>Long-form evaluation of model editing</a></p></div></main><footer class=footer><span>&copy; 2024 <a href=http://yahyakiani.github.io/blog.yahyakiani.dev/>Yahya Kayani</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>